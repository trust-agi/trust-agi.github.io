---
# Documentation: https://wowchemy.com/docs/managing-content/

title: "LSTENet: Cement productivity prediction using a self-attention spatio-temporal variational autoencoder"
authors: [Guangsi Shi, Shirui Pan, Ruiping Zou]
author_notes:
date: 2024-03-08T19:47:36+11:00
doi: ""

# Schedule page publish date (NOT publication's date).
publishDate: 2024-03-08T19:47:36+11:00

# Publication type.
# Accepts a single type but formatted as a YAML list (for Hugo requirements).
# Enter a publication type from the CSL standard.
publication_types: ["2"]

# Publication name and optional abbreviated publication name.
publication: "Powder Technology"
publication_short: ""

abstract: "In the advent of the Industry 4.0 paradigm, intelligent manufacturing has gained prominence with the integration of advanced Artificial Intelligence (AI) technologies aimed at augmenting production efficiency and mitigating operational costs. Particularly, in process industries such as cement manufacturing, the efficacy of production is intrinsically tied to the manifold process elements involved. The underlying complexity is further accentuated by the fact that the production chain is typified by a multi-variate, time-variant, and non-linear system. Such characteristics exacerbate the challenges associated with predicting the quality of final goods, especially considering the intricate physicalâ€“chemical reactions that persist even in steady states, which will reflect to the data representation. Additionally, prevailing prediction systems are impeded by their inability to assimilate ancillary spatiotemporal information, rendering their predictive accuracies suboptimal for practical production demands. Addressing these issues, this study introduces an innovative approach for online prediction of final production quality by employing a Spatiotemporal Neural Network. The core attributes of this technique encompass the extraction of latent spatial information and the effective handling of extensive temporal sequences within two main components by a variational autoencoder framework. In the variational autoencoder, it is achieved through the strategic application of learnable convolutional neural layers, supplemented by gated recurrent layers with self-attention. In a novel approach, these two fundamental components are seamlessly integrated within a single end-to-end optimization framework. Empirical evidence derived from a real-world dataset serves to substantiate the superior performance of our proposed methodology in contrast to extant machine learning algorithms. The findings are indicative of the potential that deep learning architectures harbor in addressing pragmatic challenges within industrial contexts."

# Summary. An optional shortened abstract.
summary: ""

tags: []
categories: []
featured: false

# Custom links (optional).
#   Uncomment and edit lines below to show custom links.
# links:
# - name: Follow
#   url: https://twitter.com
#   icon_pack: fab
#   icon: twitter

url_pdf:
url_code: 
url_dataset:
url_poster:
url_project:
url_slides:
url_source:
url_video:

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder. 
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ""
  focal_point: ""
  preview_only: false

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `internal-project` references `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
projects: []

# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides: "example"` references `content/slides/example/index.md`.
#   Otherwise, set `slides: ""`.
slides: ""
---
